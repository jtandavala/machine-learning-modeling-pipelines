{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building Efficient Machine Learning Pipelines: A Step-by-Step Guide"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook is inspired by the article \"[A Gentle Introduction to Machine Learning Modeling Pipelines](https://machinelearningmastery.com/machine-learning-modeling-pipelines/)\" from the Machine Learning Mastery website. It offers a practical and detailed walkthrough of how to create and implement machine learning pipelines effectively.\n",
    "\n",
    "Machine learning pipelines are essential tools that streamline the process of building models by combining multiple steps into a cohesive, repeatable workflow. This notebook will guide you through the core concepts and best practices for structuring your machine learning projects, making your workflows more efficient and easier to manage."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, we cover:\n",
    "\n",
    "- Data Preprocessing: How to prepare and clean your data for modeling, including handling missing values, scaling, and encoding categorical variables.\n",
    "\n",
    "- Feature Engineering: Transforming and selecting features to improve the performance of your model.\n",
    "\n",
    "- Model Selection: Choosing the right machine learning algorithm based on your data and problem.\n",
    "\n",
    "- Pipeline Construction: Creating pipelines that seamlessly integrate preprocessing, feature engineering, and model training.\n",
    "\n",
    "- Evaluation and Optimization: Assessing model performance and fine-tuning hyperparameters using cross-validation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What is a modeling Pipeline?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A pipeline is a linear sequence of data preparation options, modeling operations, and prediction transform operations. It allows the sequence of steps to be specified, evaluated, and used as an atomic unit."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Pipeline**: A linear sequence of data preparation and modeling steps that can be treated as an atomic unit.\n",
    "To make the idea clear, let's look at two simple examples:\n",
    "\n",
    "The first example uses data normalization for the input variables and fits a logistic regression model:\n",
    "- [Input], [Normalization], [Logistic Regression], [Predictions]\n",
    "\n",
    "The second example standardizes the input variables, applies RFE feature selection, and fits a support vector machine.\n",
    "\n",
    "- [Input], [Standardization], [RFE], [SVM], [Predictions]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation score: 0.8694063878949725\n",
      "[107114. 172390. 175274. ... 136586. 129194. 218824.]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import joblib\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler, OrdinalEncoder, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# Load the datasets\n",
    "train_df = pd.read_csv('./train.csv')\n",
    "test_df = pd.read_csv('./test.csv')\n",
    "\n",
    "# Create a validation set from the training set\n",
    "msk = np.random.rand(len(train_df)) < 0.8\n",
    "val_df = train_df[~msk]\n",
    "train_df = train_df[msk]\n",
    "\n",
    "# Define feature groups\n",
    "nominal = [\"MSZoning\", \"LotShape\", \"LandContour\", \"LotConfig\", \"Neighborhood\",\n",
    "           \"Condition1\", \"BldgType\", \"RoofStyle\",\n",
    "           \"Foundation\", \"CentralAir\", \"SaleType\", \"SaleCondition\"]\n",
    "\n",
    "ordinal = [\"LandSlope\", \"OverallQual\", \"OverallCond\", \"YearRemodAdd\",\n",
    "          \"ExterQual\", \"ExterCond\", \"BsmtQual\", \"BsmtCond\", \"BsmtExposure\",\n",
    "          \"KitchenQual\", \"Functional\", \"GarageCond\", \"PavedDrive\"]\n",
    "\n",
    "numerical = [\"LotFrontage\", \"LotArea\", \"MasVnrArea\", \"BsmtFinSF1\", \"BsmtUnfSF\",\n",
    "            \"TotalBsmtSF\", \"1stFlrSF\", \"2ndFlrSF\", \"GrLivArea\", \"GarageArea\",\n",
    "            \"OpenPorchSF\"]\n",
    "\n",
    "# Separate features and labels\n",
    "train_features = train_df[nominal + ordinal + numerical]\n",
    "train_label = train_df['SalePrice']\n",
    "\n",
    "val_features = val_df[nominal + ordinal + numerical]\n",
    "val_label = val_df['SalePrice']\n",
    "\n",
    "test_features = test_df[nominal + ordinal + numerical]\n",
    "\n",
    "# Define pipelines for different feature types\n",
    "ordinal_pipeline = Pipeline([\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "    ('encoder', OrdinalEncoder()),\n",
    "])\n",
    "\n",
    "nominal_pipeline = Pipeline([\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "    ('encoder', OneHotEncoder(sparse_output=True, handle_unknown=\"ignore\"))\n",
    "])\n",
    "\n",
    "numerical_pipeline = Pipeline([\n",
    "    ('imputer', SimpleImputer(strategy='mean')),\n",
    "    ('scaler', StandardScaler()),\n",
    "])\n",
    "\n",
    "# Create a ColumnTransformer to handle different types of features\n",
    "preprocessing_pipeline = ColumnTransformer([\n",
    "    ('nominal_preprocessor', nominal_pipeline, nominal),\n",
    "    ('ordinal_preprocessor', ordinal_pipeline, ordinal),\n",
    "    ('numerical_preprocessor', numerical_pipeline, numerical)\n",
    "])\n",
    "\n",
    "# Combine the preprocessor and the model into a complete pipeline\n",
    "complete_pipeline = Pipeline([\n",
    "    ('preprocessor', preprocessing_pipeline),\n",
    "    ('estimator', LinearRegression())\n",
    "])\n",
    "\n",
    "# Fit the pipeline on the training data and evaluate on validation data\n",
    "complete_pipeline.fit(train_features, train_label)\n",
    "score = complete_pipeline.score(val_features, val_label)\n",
    "\n",
    "# Print the validation score\n",
    "print(\"Validation score:\", score)\n",
    "\n",
    "# # Predict the sale prices for the test dataset\n",
    "# predictions = complete_pipeline.predict(test_features)\n",
    "\n",
    "pipeline_filename = 'pipeline.pkl'\n",
    "joblib.dump(complete_pipeline, pipeline_filename)\n",
    "\n",
    "pipeline = joblib.load(pipeline_filename)\n",
    "predictions = pipeline.predict(test_df)\n",
    "print(predictions)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
